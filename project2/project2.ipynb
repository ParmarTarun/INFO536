{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras as ke\n",
    "import haversine as hs   \n",
    "from haversine import Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "\n",
    "dataPath = os.path.join(\"data/\", \"*.csv\")\n",
    "files = glob(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByTime(data):\n",
    "    traj_raw = data.values[:,1:]\n",
    "    traj = np.array(sorted(traj_raw,key = lambda d:d[2]))\n",
    "    label = data.iloc[0][0]\n",
    "    return [traj,label]\n",
    "\n",
    "def reduceData(sortedData):\n",
    "    data = []\n",
    "    try:\n",
    "        for [traj, plate] in sortedData:\n",
    "            distanceUnoccupied = 0\n",
    "            distanceOccupied = 0\n",
    "            prevLong = traj[0][0]\n",
    "            prevLat = traj[0][1]\n",
    "            for row in traj:\n",
    "                try:\n",
    "                    if (row[-1] == 0):\n",
    "                        distanceUnoccupied += hs.haversine(\n",
    "                            (prevLat, prevLong), (row[1], row[0]), unit=Unit.KILOMETERS)\n",
    "                    else:\n",
    "                        distanceOccupied += hs.haversine((prevLat, prevLong),\n",
    "                                                        (row[1], row[0]), unit=Unit.KILOMETERS)\n",
    "                except Exception as e:\n",
    "                    print(\"Skipping Invalid data point\",row)\n",
    "                prevLat = row[1]\n",
    "                prevLong = row[0]\n",
    "            data.append([distanceOccupied, distanceUnoccupied, plate])\n",
    "    except:\n",
    "        print(\"Skipping Invalid Data with len:\",len(sortedData))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Invalid data point [246.000793 16.295 '2016-11-26 11:00:00' 0]\n",
      "Skipping Invalid data point [114.164551 22.566833 '2016-11-26 11:00:06' 0]\n",
      "Skipping Invalid data point [767.0096599999999 128.028 '2016-12-09 20:26:09' 0]\n",
      "Skipping Invalid data point [114.117569 22.544268 '2016-12-09 20:26:36' 0]\n",
      "Skipping Invalid Data with len: 0\n",
      "Skipping Invalid data point [290.5175 162.028 '2016-12-11 11:10:09' 0]\n",
      "Skipping Invalid data point [114.135216 22.55825 '2016-12-11 11:10:22' 0]\n",
      "Skipping Invalid data point [262.117 12102.8 '2016-11-25 18:30:41' 0]\n",
      "Skipping Invalid data point [114.1464 22.555567 '2016-11-25 18:30:44' 1]\n",
      "Skipping Invalid data point [100.267 28028.0 '2016-12-10 22:34:23' 1]\n",
      "Skipping Invalid data point [113.961121 22.55295 '2016-12-10 22:34:36' 0]\n"
     ]
    }
   ],
   "source": [
    "# remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "combinedData = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    groupData = df.groupby('plate')\n",
    "    sortedData = groupData.apply(sortByTime)\n",
    "    combinedData.extend(reduceData(sortedData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupied</th>\n",
       "      <th>unoccupied</th>\n",
       "      <th>plate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.344354</td>\n",
       "      <td>145.465781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261.753492</td>\n",
       "      <td>174.031607</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>323.302293</td>\n",
       "      <td>226.395005</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386.068903</td>\n",
       "      <td>145.777275</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>266.352191</td>\n",
       "      <td>267.222992</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>219.909586</td>\n",
       "      <td>173.813741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>308.335977</td>\n",
       "      <td>131.811883</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>323.237094</td>\n",
       "      <td>177.092570</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>222.662593</td>\n",
       "      <td>131.444884</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>296.106018</td>\n",
       "      <td>150.249425</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     occupied  unoccupied  plate\n",
       "0  245.344354  145.465781    0.0\n",
       "1  261.753492  174.031607    1.0\n",
       "2  323.302293  226.395005    2.0\n",
       "3  386.068903  145.777275    3.0\n",
       "4  266.352191  267.222992    4.0\n",
       "5  219.909586  173.813741    0.0\n",
       "6  308.335977  131.811883    1.0\n",
       "7  323.237094  177.092570    2.0\n",
       "8  222.662593  131.444884    3.0\n",
       "9  296.106018  150.249425    4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData = np.array(combinedData)\n",
    "newDataFrame = pd.DataFrame(newData, columns = ['occupied','unoccupied','plate'])\n",
    "newDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = newDataFrame[['occupied', 'unoccupied']]\n",
    "y = newDataFrame[['plate']]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xScaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xScaled, y, test_size=0.2, random_state=12, shuffle=True)\n",
    "\n",
    "yTrain = ke.utils.to_categorical(y_train)\n",
    "yTest = ke.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                192       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83013 (324.27 KB)\n",
      "Trainable params: 83013 (324.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers as lr\n",
    "\n",
    "network = ke.models.Sequential()\n",
    "\n",
    "network.add(lr.Dense(64, input_dim=2))\n",
    "network.add(lr.Activation('tanh'))\n",
    "\n",
    "network.add(lr.Dense(128))\n",
    "\n",
    "network.add(lr.Dense(256))\n",
    "network.add(lr.Activation('relu'))\n",
    "\n",
    "network.add(lr.Dense(128))\n",
    "network.add(lr.Activation('tanh'))\n",
    "\n",
    "network.add(lr.Dense(64))\n",
    "network.add(lr.Activation('relu'))\n",
    "\n",
    "network.add(lr.Dense(5))\n",
    "network.add(lr.Activation('softmax'))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 1.6118 - accuracy: 0.1728\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6083 - accuracy: 0.1952\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5979 - accuracy: 0.2612\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5801 - accuracy: 0.2360\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5582 - accuracy: 0.2809\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5433 - accuracy: 0.2767\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5321 - accuracy: 0.2809\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5284 - accuracy: 0.3090\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5235 - accuracy: 0.3104\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5160 - accuracy: 0.3062\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4992 - accuracy: 0.3202\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5048 - accuracy: 0.3090\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4977 - accuracy: 0.3244\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4983 - accuracy: 0.2935\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4643 - accuracy: 0.3581\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4601 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4531 - accuracy: 0.3385\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4331 - accuracy: 0.3567\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4420 - accuracy: 0.3624\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4432 - accuracy: 0.3778\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4554 - accuracy: 0.3553\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4374 - accuracy: 0.3736\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4818 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4405 - accuracy: 0.3694\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4202 - accuracy: 0.3904\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4358 - accuracy: 0.3638\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4275 - accuracy: 0.3778\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4089 - accuracy: 0.3820\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4337 - accuracy: 0.3652\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4147 - accuracy: 0.3933\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4058 - accuracy: 0.3764\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4037 - accuracy: 0.3904\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4177 - accuracy: 0.3989\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4046 - accuracy: 0.4059\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4039 - accuracy: 0.3862\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3877 - accuracy: 0.4157\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3996 - accuracy: 0.4129\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4078 - accuracy: 0.3947\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3894 - accuracy: 0.4115\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4063 - accuracy: 0.3933\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3891 - accuracy: 0.3961\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4205 - accuracy: 0.3525\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4237 - accuracy: 0.3890\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3872 - accuracy: 0.4199\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4263 - accuracy: 0.3666\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4072 - accuracy: 0.3652\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4098 - accuracy: 0.3890\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3981 - accuracy: 0.3989\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3870 - accuracy: 0.3933\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3827 - accuracy: 0.4157\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3871 - accuracy: 0.3975\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3844 - accuracy: 0.3933\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3890 - accuracy: 0.3876\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3856 - accuracy: 0.3961\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3819 - accuracy: 0.3890\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3924 - accuracy: 0.4017\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4033 - accuracy: 0.3694\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3887 - accuracy: 0.3961\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3738 - accuracy: 0.4115\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3858 - accuracy: 0.3919\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3729 - accuracy: 0.4101\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3904 - accuracy: 0.4045\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4306 - accuracy: 0.3638\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3940 - accuracy: 0.4059\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3784 - accuracy: 0.4073\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3799 - accuracy: 0.4017\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3859 - accuracy: 0.4073\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3900 - accuracy: 0.3975\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3766 - accuracy: 0.4059\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3868 - accuracy: 0.3890\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3850 - accuracy: 0.3961\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3643 - accuracy: 0.4157\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3820 - accuracy: 0.4115\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3723 - accuracy: 0.3975\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3694 - accuracy: 0.4101\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3716 - accuracy: 0.4171\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3585 - accuracy: 0.4031\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3715 - accuracy: 0.4143\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3776 - accuracy: 0.3848\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3669 - accuracy: 0.4017\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3655 - accuracy: 0.3947\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3560 - accuracy: 0.4228\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3825 - accuracy: 0.3904\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3536 - accuracy: 0.4087\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3675 - accuracy: 0.4129\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3588 - accuracy: 0.3947\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3717 - accuracy: 0.3947\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3743 - accuracy: 0.3975\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3594 - accuracy: 0.4115\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3537 - accuracy: 0.4143\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3814 - accuracy: 0.4143\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3626 - accuracy: 0.4228\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3754 - accuracy: 0.3919\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3593 - accuracy: 0.4129\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3604 - accuracy: 0.4157\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3796 - accuracy: 0.3919\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3599 - accuracy: 0.4101\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3751 - accuracy: 0.3933\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3975 - accuracy: 0.4031\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3582 - accuracy: 0.4242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f03ac1052a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(x_train, yTrain, epochs=100, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.save(\"mymodel.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ke.models.load_model('mymodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 1.4984 - accuracy: 0.3371\n",
      "\n",
      "Test accuracy: 33.7%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, yTest, batch_size=15)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle('test.pkl')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process testdata\n",
    "distanceUnoccupied = 0\n",
    "distanceOccupied = 0\n",
    "prevLong = test_data[0][0]\n",
    "prevLat = test_data[0][1]\n",
    "testing = []\n",
    "for row in test_data:\n",
    "    try:\n",
    "        if (row[-1] == 0):\n",
    "            distanceUnoccupied += hs.haversine(\n",
    "                (prevLat, prevLong), (row[1], row[0]), unit=Unit.KILOMETERS)\n",
    "        else:\n",
    "            distanceOccupied += hs.haversine((prevLat, prevLong),\n",
    "                                            (row[1], row[0]), unit=Unit.KILOMETERS)\n",
    "    except Exception as e:\n",
    "        print(\"Invalid data point\", row)\n",
    "    prevLat = row[1]\n",
    "    prevLong = row[0]\n",
    "testing.append([distanceOccupied, distanceUnoccupied])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "testingScaled = min_max_scaler.fit_transform(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testingScaled)[0]\n",
    "plate = predictions.argmax()+1\n",
    "print(plate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
